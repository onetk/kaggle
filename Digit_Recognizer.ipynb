{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mnist.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["qqHFQtFjvq2m"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"MXOmcFBXhNSK","colab_type":"text"},"cell_type":"markdown","source":["##    第1章　API周りの初期設定\n","---\n","\n"]},{"metadata":{"id":"Jd2v125FhbXm","colab_type":"text"},"cell_type":"markdown","source":["**はじめに[Kaggle](https://www.kaggle.com/)のアカウントからAPIを使うためにjson持ってきて入れましょう**"]},{"metadata":{"id":"KUPag7sLiPFY","colab_type":"code","outputId":"0183f367-93c8-4d22-93d8-94101e4d16e9","executionInfo":{"status":"ok","timestamp":1539766593097,"user_tz":-540,"elapsed":33563,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-a8de3e3e-05b7-48ce-a365-93a10fc62516\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-a8de3e3e-05b7-48ce-a365-93a10fc62516\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{}"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"xgi157XKhYlI","colab_type":"text"},"cell_type":"markdown","source":["**jsonを入れれたらcolab上で使えるように権限を変えましょう**"]},{"metadata":{"id":"GeQ16ANYhRt4","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!ls -l /root/.kaggle\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O0muYvNqhfFV","colab_type":"text"},"cell_type":"markdown","source":["## 第2章　ライブラリの追加\n","\n","---\n","\n"]},{"metadata":{"id":"19O5gLLPhrM9","colab_type":"text"},"cell_type":"markdown","source":["**今回はNNの定義にkerasを使うのでKerasを入れます。後は予測データを直接kaggleにアップするのでkaggleも入れます。**"]},{"metadata":{"id":"2BAt45k7mBC_","colab_type":"code","outputId":"67aec0c5-42dd-41c7-9be6-ed1e59b861af","executionInfo":{"status":"ok","timestamp":1539760243210,"user_tz":-540,"elapsed":3990,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"cell_type":"code","source":["!pip install -q keras\n","!pip install -q kaggle\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading train.csv to /content\n"," 68% 50.0M/73.2M [00:00<00:00, 84.2MB/s]\n","100% 73.2M/73.2M [00:00<00:00, 166MB/s] \n","Downloading test.csv to /content\n"," 86% 42.0M/48.8M [00:00<00:00, 79.4MB/s]\n","100% 48.8M/48.8M [00:00<00:00, 150MB/s] \n","Downloading sample_submission.csv to /content\n","  0% 0.00/235k [00:00<?, ?B/s]\n","100% 235k/235k [00:00<00:00, 25.1MB/s]\n"],"name":"stdout"}]},{"metadata":{"id":"HiX9UJWXhv1Z","colab_type":"text"},"cell_type":"markdown","source":["**これでKaggleのAPIが使えるようになったので、早速 train/test データをダウンロードしましょう**"]},{"metadata":{"id":"YwD0qAc_mEpn","colab_type":"code","colab":{}},"cell_type":"code","source":["!kaggle competitions download -c digit-recognizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RJv5eaHOmi6a","colab_type":"text"},"cell_type":"markdown","source":["## 第3章　実際にやってみる\n","---"]},{"metadata":{"id":"R_TT85SFh5Cy","colab_type":"text"},"cell_type":"markdown","source":["**最初にライブラリをインポートしましょう**"]},{"metadata":{"id":"TPmP6Zdhmh_j","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# keras\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from keras.layers.advanced_activations import LeakyReLU \n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.np_utils import to_categorical\n","from keras.optimizers import SGD, RMSprop\n","from keras.callbacks import ReduceLROnPlateau  \n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7tBB7u6ivwSX","colab_type":"text"},"cell_type":"markdown","source":["**データを読み込んで正規化、ラベル等の前処理を行います。**"]},{"metadata":{"id":"x4yEGGkfmt1v","colab_type":"code","colab":{}},"cell_type":"code","source":["# load training & test datasets\n","train = pd.read_csv(\"/content/train.csv\")\n","test = pd.read_csv(\"/content/test.csv\")\n","\n","# pandas to numpy\n","Y_train = train[\"label\"]\n","X_train = train.drop(labels=[\"label\"], axis=1)\n","\n","del train\n","\n","# normalize\n","X_train = X_train/255.0\n","test = test/255.0\n","\n","# reshape the data so that the data\n","# represents (label, img_rows, img_cols, grayscale)\n","X_train = X_train.values.reshape(-1, 28, 28, 1)\n","test = test.values.reshape(-1, 28, 28, 1)\n","\n","# one-hot vector as a label\n","Y_train = to_categorical(Y_train, num_classes=10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jGTWPBc4vkx8","colab_type":"text"},"cell_type":"markdown","source":["**CNNの層構成を定義します。**"]},{"metadata":{"id":"bsPnw-NLm0Rq","colab_type":"code","outputId":"052c95a6-dfc2-4684-fa91-3f90962fb560","executionInfo":{"status":"ok","timestamp":1539760336849,"user_tz":-540,"elapsed":945,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"base_uri":"https://localhost:8080/","height":850}},"cell_type":"code","source":["# set the CNN No.1\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n","model.add(BatchNormalization(axis=-1))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(BatchNormalization(axis=-1))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(64,(3, 3)))\n","model.add(BatchNormalization(axis=-1))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(BatchNormalization(axis=-1))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","\n","# Fully connected layer\n","model.add(Dense(512))\n","model.add(BatchNormalization())\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(10))\n","\n","model.add(Activation('softmax'))\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 26, 26, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 24, 24, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 24, 24, 32)        128       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 24, 24, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 10, 10, 64)        18496     \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 10, 10, 64)        256       \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 8, 8, 64)          36928     \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 597,738\n","Trainable params: 596,330\n","Non-trainable params: 1,408\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"HN6cMRfFjMfw","colab_type":"text"},"cell_type":"markdown","source":["**先ほどのモデルを使用して、10クラス分類を行う設定にします。また、画像拡張を行います。**"]},{"metadata":{"id":"DhqrzoWlm6ki","colab_type":"code","colab":{}},"cell_type":"code","source":["# compile model\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# cross validation\n","X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.10, random_state=1220)\n","\n","# learning rate\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n","\n","# data argumentation\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","train_generator = gen.flow(X_train, Y_train, batch_size=64)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a0xA2_wVjbvv","colab_type":"text"},"cell_type":"markdown","source":["**実際に回します。**"]},{"metadata":{"id":"RineJ1tynOQt","colab_type":"code","outputId":"60ad28d7-713c-4fee-8a29-ebc3f93b2c48","executionInfo":{"status":"ok","timestamp":1539757814541,"user_tz":-540,"elapsed":7,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"base_uri":"https://localhost:8080/","height":1955}},"cell_type":"code","source":["# model training\n","model.fit_generator(train_generator, epochs=30, validation_data = (X_val, Y_val), verbose=2, steps_per_epoch=X_train.shape[0]/36,\n","                                       callbacks=[learning_rate_reduction])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n"," - 30s - loss: 0.1146 - acc: 0.9640 - val_loss: 0.0671 - val_acc: 0.9825\n","Epoch 2/50\n"," - 28s - loss: 0.0477 - acc: 0.9850 - val_loss: 0.0450 - val_acc: 0.9881\n","Epoch 3/50\n"," - 28s - loss: 0.0410 - acc: 0.9876 - val_loss: 0.0746 - val_acc: 0.9852\n","Epoch 4/50\n"," - 28s - loss: 0.0331 - acc: 0.9899 - val_loss: 0.0321 - val_acc: 0.9923\n","Epoch 5/50\n"," - 28s - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0317 - val_acc: 0.9892\n","Epoch 6/50\n"," - 28s - loss: 0.0285 - acc: 0.9918 - val_loss: 0.0385 - val_acc: 0.9915\n","Epoch 7/50\n"," - 28s - loss: 0.0253 - acc: 0.9928 - val_loss: 0.0177 - val_acc: 0.9952\n","Epoch 8/50\n"," - 28s - loss: 0.0267 - acc: 0.9924 - val_loss: 0.0344 - val_acc: 0.9921\n","Epoch 9/50\n"," - 28s - loss: 0.0240 - acc: 0.9931 - val_loss: 0.0288 - val_acc: 0.9944\n","Epoch 10/50\n"," - 28s - loss: 0.0220 - acc: 0.9935 - val_loss: 0.0378 - val_acc: 0.9934\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 11/50\n"," - 28s - loss: 0.0155 - acc: 0.9955 - val_loss: 0.0292 - val_acc: 0.9942\n","Epoch 12/50\n"," - 28s - loss: 0.0133 - acc: 0.9962 - val_loss: 0.0187 - val_acc: 0.9952\n","Epoch 13/50\n"," - 28s - loss: 0.0109 - acc: 0.9969 - val_loss: 0.0209 - val_acc: 0.9955\n","Epoch 14/50\n"," - 28s - loss: 0.0120 - acc: 0.9965 - val_loss: 0.0249 - val_acc: 0.9958\n","Epoch 15/50\n"," - 28s - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0238 - val_acc: 0.9952\n","Epoch 16/50\n"," - 27s - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0278 - val_acc: 0.9947\n","Epoch 17/50\n"," - 26s - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0177 - val_acc: 0.9955\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 18/50\n"," - 27s - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0143 - val_acc: 0.9966\n","Epoch 19/50\n"," - 26s - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0223 - val_acc: 0.9955\n","Epoch 20/50\n"," - 25s - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0266 - val_acc: 0.9944\n","Epoch 21/50\n"," - 25s - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0258 - val_acc: 0.9952\n","\n","Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 22/50\n"," - 26s - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0207 - val_acc: 0.9952\n","Epoch 23/50\n"," - 27s - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0197 - val_acc: 0.9958\n","Epoch 24/50\n"," - 27s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0198 - val_acc: 0.9955\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","Epoch 25/50\n"," - 28s - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0214 - val_acc: 0.9955\n","Epoch 26/50\n"," - 26s - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0215 - val_acc: 0.9952\n","Epoch 27/50\n"," - 26s - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0228 - val_acc: 0.9963\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","Epoch 28/50\n"," - 26s - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0203 - val_acc: 0.9955\n","Epoch 29/50\n"," - 26s - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0212 - val_acc: 0.9960\n","Epoch 30/50\n"," - 26s - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0217 - val_acc: 0.9960\n","\n","Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","Epoch 31/50\n"," - 26s - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0214 - val_acc: 0.9963\n","Epoch 32/50\n"," - 26s - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0213 - val_acc: 0.9963\n","Epoch 33/50\n"," - 25s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0213 - val_acc: 0.9963\n","\n","Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-05.\n","Epoch 34/50\n"," - 26s - loss: 0.0048 - acc: 0.9990 - val_loss: 0.0211 - val_acc: 0.9963\n","Epoch 35/50\n"," - 26s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0213 - val_acc: 0.9958\n","Epoch 36/50\n"," - 26s - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0210 - val_acc: 0.9960\n","Epoch 37/50\n"," - 27s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0206 - val_acc: 0.9963\n","Epoch 38/50\n"," - 27s - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0210 - val_acc: 0.9966\n","Epoch 39/50\n"," - 26s - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0210 - val_acc: 0.9958\n","Epoch 40/50\n"," - 25s - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0209 - val_acc: 0.9963\n","Epoch 41/50\n"," - 26s - loss: 0.0040 - acc: 0.9991 - val_loss: 0.0214 - val_acc: 0.9960\n","Epoch 42/50\n"," - 26s - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0210 - val_acc: 0.9958\n","Epoch 43/50\n"," - 25s - loss: 0.0038 - acc: 0.9991 - val_loss: 0.0212 - val_acc: 0.9963\n","Epoch 44/50\n"," - 26s - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0209 - val_acc: 0.9966\n","Epoch 45/50\n"," - 26s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0208 - val_acc: 0.9963\n","Epoch 46/50\n"," - 28s - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0209 - val_acc: 0.9960\n","Epoch 47/50\n"," - 26s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0210 - val_acc: 0.9963\n","Epoch 48/50\n"," - 26s - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0208 - val_acc: 0.9963\n","Epoch 49/50\n"," - 26s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0208 - val_acc: 0.9966\n","Epoch 50/50\n"," - 26s - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0212 - val_acc: 0.9963\n"],"name":"stdout"}]},{"metadata":{"id":"kEq8QWHkkhb8","colab_type":"text"},"cell_type":"markdown","source":["## 第4章　提出してみる\n","\n","\n","---\n"]},{"metadata":{"id":"DG9dTMfuwAiF","colab_type":"text"},"cell_type":"markdown","source":["**学習したモデルでtestデータの予測をします。**"]},{"metadata":{"id":"YKhtb6v6kk6M","colab_type":"code","colab":{}},"cell_type":"code","source":["# model prediction on test data\n","predictions = model.predict_classes(test, verbose=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wMMdFCbyk1ec","colab_type":"text"},"cell_type":"markdown","source":["**predictionをcsvに変換して提出、完了です。**"]},{"metadata":{"id":"oZVl7rlBnT84","colab_type":"code","outputId":"1ce2c328-ea09-463e-9133-4e68c96cee99","executionInfo":{"status":"ok","timestamp":1539757841232,"user_tz":-540,"elapsed":5302,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# make a submission file\n","submissions = pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n","submissions.to_csv(\"my_submission.csv\", index=False, header=True)\n","\n","# submit the file to kaggle\n","!kaggle competitions submit digit-recognizer -f my_submission.csv -m \"ok Google Colab!\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Successfully submitted to Digit Recognizer"],"name":"stdout"}]},{"metadata":{"id":"qqHFQtFjvq2m","colab_type":"text"},"cell_type":"markdown","source":["### 番外編です。GPUではなく、TPUを使ったモデルでやってみます。\n","---"]},{"metadata":{"id":"2mOcHDeLh_u8","colab_type":"text"},"cell_type":"markdown","source":["**※TPUを使用する場合です。TensorflowのバックエンドとしてKerasを使うので、ライブラリを再び設定します。**"]},{"metadata":{"id":"wiOlHsmD0Xjs","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from tensorflow.contrib.tpu.python.tpu import keras_support\n","# from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, AveragePooling2D, Dense, Dropout, Flatten, MaxPooling2D\n","# from tensorflow.keras.models import Model, Sequential\n","# from tensorflow.keras.utils import to_categorical\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n","from tensorflow.keras.layers import ThresholdedReLU \n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import SGD, RMSprop\n","from tensorflow.keras.callbacks import ReduceLROnPlateau  \n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GCTWCJAbkHRD","colab_type":"text"},"cell_type":"markdown","source":["**少しネットワーク構成を変えます**"]},{"metadata":{"id":"JMIQRSLBuu0c","colab_type":"code","outputId":"e3874519-89f8-480d-dafa-5951345e4e22","executionInfo":{"status":"ok","timestamp":1539759147679,"user_tz":-540,"elapsed":1481,"user":{"displayName":"Taka N","photoUrl":"","userId":"04623064719375199771"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"cell_type":"code","source":["# Set the CNN model No2\n","\n","model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (28,28,1)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation = \"softmax\"))\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_39 (Conv2D)           (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","conv2d_40 (Conv2D)           (None, 28, 28, 32)        25632     \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_41 (Conv2D)           (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","conv2d_42 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_20 (MaxPooling (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 3136)              0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 256)               803072    \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                2570      \n","=================================================================\n","Total params: 887,530\n","Trainable params: 887,530\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"K6kYFGVdkXLo","colab_type":"text"},"cell_type":"markdown","source":["**先ほどのモデルを使用して、10クラス分類を行う設定にします。また、画像拡張を行います。**"]},{"metadata":{"id":"qfE8uW30wQzG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define the optimizer\n","optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","\n","# Compile the model\n","model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# Set a learning rate annealer\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.00001)\n","\n","datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False)  # randomly flip images\n","\n","\n","datagen.fit(X_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5o9QMt37kam2","colab_type":"text"},"cell_type":"markdown","source":["**実際に回します。**"]},{"metadata":{"id":"CvJ5g_ibwvea","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fit the model\n","history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=64), epochs = 30, validation_data = (X_val,Y_val),\n","                              verbose = 2, steps_per_epoch=X_train.shape[0], callbacks=[learning_rate_reduction])"],"execution_count":0,"outputs":[]}]}